[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An (opinionated) introduction to R for biologists",
    "section": "",
    "text": "For a more gentle introduction to R and its basics, check the book Hands-On Programming with R.\nIf you are familiar with R already and want to go deeper with the tidyverse functions, take a look at the book R for Data Science."
  },
  {
    "objectID": "chapters/loading.html",
    "href": "chapters/loading.html",
    "title": "2  Loading your data",
    "section": "",
    "text": "The first step in any data analysis is to open up your favorite software and load the data up. You are probably familiar with user interfaces, where you click some buttons, you upload your excel file and voilá, data is ready to analyse.\nIn this chapter I will teach you how to format your qPCR data so you can load it easily to R. I will also show you how to load the data itself."
  },
  {
    "objectID": "chapters/loading.html#formats-formats-and-more-formats",
    "href": "chapters/loading.html#formats-formats-and-more-formats",
    "title": "2  Loading your data",
    "section": "2.1 Formats, formats and more formats…",
    "text": "2.1 Formats, formats and more formats…\nIf you are here, you are probably used to excel and the format xlsx. R can open these files, however, it is easier to run your analysis if you have your data in the csv format. For qPCR specially, each qPCR machine, the excel sheet will be different and not in a standard format. Usually it is a table with several cells containing information regarding your run and other parameters.\nGiven your fresh table from the qPCR machine, we will extract some columns. In qPCR experiments, usually there are three technical replicates for your samples. This is reflected in how the data is saved.\nAn example table is shown in the data folder."
  },
  {
    "objectID": "chapters/loading.html#how-to-load-your-data",
    "href": "chapters/loading.html#how-to-load-your-data",
    "title": "2  Loading your data",
    "section": "2.2 How to load your data",
    "text": "2.2 How to load your data\nIf you saved your table as a csv file, then we have several options to load the file. You can use the function read.csv or read.table from base R to open the tables. The way to use these functions is shown below.\n\nqpcr <- read.csv(\"../data/qPCR.csv\")\nqpcr <- read.table(\"../data/qPCR.csv\", sep = \",\", header = TRUE)\n\nNote that for read.table we need to specify the separator, in this case it is a comma (“,”) and we also specify HEADER = TRUE. This means the first row of your table is the header of your data frame. In general if you have a csv file, it is easier to run read.csv."
  },
  {
    "objectID": "chapters/loading.html#checking-the-data",
    "href": "chapters/loading.html#checking-the-data",
    "title": "2  Loading your data",
    "section": "2.3 Checking the data",
    "text": "2.3 Checking the data\nWhen loading the data, it is very important to check if it was imported successfully or any problem happened. A package that we will be using throughout this book is dplyr. Within dplyr we have some functions that help us deal data frames in a very intuitive way. The first function we will use here to check the data is glimpse. We load the package here, but it is best practice to load all the packages you will be using at the beginning of your analysis.\n\n# first we start by loading the library\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n# we now use the function glimpse on our dataframe\nglimpse(qpcr)\n\nRows: 72\nColumns: 4\n$ sample.ID <int> 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, …\n$ group     <chr> \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT …\n$ gene      <chr> \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT…\n$ ct        <dbl> 16.49, 16.44, 16.65, 16.50, 16.74, 16.68, 16.96, 16.92, 17.0…\n\n\nThe function glimpse displays a summary of each column of your dataframe and their data types. We see that sample_id is an integer, group and gene are characters and finally the ct values are doubles, meaning they are numeric. So far the data looks good.\nAnother way to use the function glimpse and other functions from the dplyr package is using the pipe %>%. The way to interpret the pipe is the following. Given a dataframe, we pipe the dataframe to the next function. The syntax is shown in the code block below.\n\nqpcr %>% glimpse\n\nRows: 72\nColumns: 4\n$ sample.ID <int> 20, 20, 20, 21, 21, 21, 22, 22, 22, 23, 23, 23, 24, 24, 24, …\n$ group     <chr> \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT C\", \"WT …\n$ gene      <chr> \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT\", \"AKT…\n$ ct        <dbl> 16.49, 16.44, 16.65, 16.50, 16.74, 16.68, 16.96, 16.92, 17.0…\n\n\nThe output is the same as before, the difference is that we can use other functions and chain them together. For example, if we want to see only the first 5 rows of the table and then select the row with maximum ct value, we can use the function head followed by slice_max.\n\nqpcr %>% \n    head %>%\n    slice_max(order_by = ct) # specify the column by passing the name without quotes\n\n  sample.ID group gene    ct\n1        21  WT C  AKT 16.74\n\n\nThere is a flow of code when chaining functions like this. By also writing code like this, it is easier to modify or add new steps to the chain."
  },
  {
    "objectID": "chapters/loading.html#checkpoint",
    "href": "chapters/loading.html#checkpoint",
    "title": "2  Loading your data",
    "section": "2.4 Checkpoint",
    "text": "2.4 Checkpoint\nWe now use readRDS to save our current matrix to load it up in the next chapter. The checkpoints are not necessary. As this is a simple analysis, you can run everything in a single script and loaded in your memory. The good thing about checkpoints is that you can save heavy calculations so you do not need to perform them again.\n\nsaveRDS(qpcr, \"../checkpoints/loading/qpcr.rds\")\n\n\n\n\n\n\n\nTip\n\n\n\nreadRDS is a function that lets you save R objects into your computer. It is extremely handy when you want to save expensive calculations or continue your analysis later. Note you are only saving one object.\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are using quarto markdown or Rmarkdown, there is a chunk option that you can use to not rerun that chunk, namely the cache option.\n\n\nFor each checkpoint, we save them in a specific folder for each chapter inside checkpoints, in the root folder. This ensures we know where the data was generated by pointing to the name of the chapter."
  },
  {
    "objectID": "chapters/cleaning.html",
    "href": "chapters/cleaning.html",
    "title": "3  Cleaning your data",
    "section": "",
    "text": "In this chapter we will go over how you can clean your data before you start any analysis. Doing this before anything else will save you a lot of time. It is very frequent that you need to change a variable name or create a new column in your dataframe. By performing the cleaning and modifications before doing any plotting, it helps to ensure you will be using clean data and it will make your life easier."
  },
  {
    "objectID": "chapters/cleaning.html#loading-libraries-and-files",
    "href": "chapters/cleaning.html#loading-libraries-and-files",
    "title": "3  Cleaning your data",
    "section": "3.1 Loading libraries and files",
    "text": "3.1 Loading libraries and files\nAs discussed before, we start by loading the libraries we will use. In this section we will go over the packages janitor, stringr and tidyr.\n\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(janitor)\nlibrary(tidyr)\n\nAnd we load up our qPCR data saved from the checkpoint. To do this we use the function readRDS. For this we only specify the path to where the checkpoint was saved.\n\nqpcr <- readRDS(\"../checkpoints/loading/qpcr.rds\")"
  },
  {
    "objectID": "chapters/cleaning.html#formatting-your-column-names",
    "href": "chapters/cleaning.html#formatting-your-column-names",
    "title": "3  Cleaning your data",
    "section": "3.2 Formatting your column names",
    "text": "3.2 Formatting your column names\nWhenever doing analysis on R it is important to have sound column names. They make data wrangling easier. Moreover, when you repeat the analysis over and over again, having sane names for your columns makes your code cleaner. There is a very neat package in R that helps cleaning your column names and suggesting new names: janitor. In this package there is the function clean_names that changes all column names to lower case, change spaces and dots to underscores and much more. The idea is that you have very clear names without any non conventional character.\nThe qPCR dataframe has the following columns:\n\ncolnames(qpcr)\n\n[1] \"sample.ID\" \"group\"     \"gene\"      \"ct\"       \n\n\nThe column sample.ID has both lower and upper case. This does not help when referencing and makes reading more difficult.\n\nqpcr <- qpcr %>% janitor::clean_names()\n\ncolnames(qpcr)\n\n[1] \"sample_id\" \"group\"     \"gene\"      \"ct\"       \n\n\nThe column was changed from sample.ID to sample_id."
  },
  {
    "objectID": "chapters/cleaning.html#changing-values-in-a-column",
    "href": "chapters/cleaning.html#changing-values-in-a-column",
    "title": "3  Cleaning your data",
    "section": "3.3 Changing values in a column",
    "text": "3.3 Changing values in a column\nWe saw previously that the column group contains the knockout and treatment assignments. This would be better if it was in different columns. Notice that these two information are separated by a space in the group column. To split them, we use the function separate from tidyr.\n\nqpcr <- qpcr %>% \n    # set the argument remove to FALSE so the column is not removed\n    # from the dataframe\n    separate(col = \"group\", into = c(\"genotype\", \"treatment\"), remove = FALSE)\n\nqpcr %>% head\n\n  sample_id group genotype treatment gene    ct\n1        20  WT C       WT         C  AKT 16.49\n2        20  WT C       WT         C  AKT 16.44\n3        20  WT C       WT         C  AKT 16.65\n4        21  WT C       WT         C  AKT 16.50\n5        21  WT C       WT         C  AKT 16.74\n6        21  WT C       WT         C  AKT 16.68\n\n\nNote that the samples have an ID, and they are represented by integers. Actually it would be better if this columns is represented by factors. This is actually very important when doing linear modelling. If a column is numeric, or integers, R will estimate the parameters as if the variable is continuous, whereas it should be a group for example.\nTo modify one column we can use the function mutate from dplyr. We use the function factor to convert a numeric vector into a categorical vector.\n\nqpcr <- qpcr %>%\n    mutate(sample_id = factor(sample_id))\n\nclass(qpcr[, \"sample_id\"])\n\n[1] \"factor\""
  },
  {
    "objectID": "chapters/cleaning.html#checkpoint",
    "href": "chapters/cleaning.html#checkpoint",
    "title": "3  Cleaning your data",
    "section": "3.4 Checkpoint",
    "text": "3.4 Checkpoint\nWe are ready to proceed to the next steps. Before that we save once again our data. You can either overwrite or create a new object. For the sake of clarity, we always save a new object. Sometimes this is not useful because the objects are big, so you want to actually overwrite the previous rds object.\n\nsaveRDS(qpcr, \"../checkpoints/cleaning/qpcr.rds\")"
  },
  {
    "objectID": "chapters/preparing.html",
    "href": "chapters/preparing.html",
    "title": "4  Preparing the data",
    "section": "",
    "text": "Describe data needs to be in special format to do stuff in R, explain pivoting. Explain groupping as well, which makes it easier to do average calculations\nIn this chapter we start checking and preparing the data for future exploration. The qPCR data is special, as we always have technical replicates, meaning we have multiple measures of the same sample material. One common step is to average the cycle threshold values of each sample to get a final value. This usually works pretty well, provided there is no outlier. Therefore, it is important to explore the data and understand what it looks like.\nThe following sections will show you how to do some preliminary checks of the data and how to create summaries so we can do some plots and statistical analysis."
  },
  {
    "objectID": "chapters/preparing.html#loading-libraries-and-files",
    "href": "chapters/preparing.html#loading-libraries-and-files",
    "title": "4  Preparing the data",
    "section": "4.1 Loading libraries and files",
    "text": "4.1 Loading libraries and files\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gtsummary)\n\nqpcr <- readRDS(\"../checkpoints/cleaning/qpcr.rds\")"
  },
  {
    "objectID": "chapters/preparing.html#exploring-some-statistics",
    "href": "chapters/preparing.html#exploring-some-statistics",
    "title": "4  Preparing the data",
    "section": "4.2 Exploring some statistics",
    "text": "4.2 Exploring some statistics\nWe first start by checking the structure of the dataset, number of samples by ID, treatment, genotype and more. For this we can pipe the qpcr dataframe to the function tbl_summary from the package gtsummary. A nice package to use when writing reports.\n\nqpcr %>% gtsummary::tbl_summary()\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 721\n    \n  \n  \n    sample_id\n\n        20\n6 (8.3%)\n        21\n6 (8.3%)\n        22\n6 (8.3%)\n        23\n6 (8.3%)\n        24\n6 (8.3%)\n        25\n6 (8.3%)\n        26\n6 (8.3%)\n        27\n6 (8.3%)\n        28\n6 (8.3%)\n        29\n6 (8.3%)\n        30\n6 (8.3%)\n        31\n6 (8.3%)\n    group\n\n        KO C\n18 (25%)\n        KO T\n18 (25%)\n        WT C\n18 (25%)\n        WT T\n18 (25%)\n    genotype\n\n        KO\n36 (50%)\n        WT\n36 (50%)\n    treatment\n\n        C\n36 (50%)\n        T\n36 (50%)\n    gene\n\n        AKT\n36 (50%)\n        GAPDH\n36 (50%)\n    ct\n17.28 (17.15, 17.65)\n  \n  \n  \n    \n      1 n (%); Median (IQR)\n    \n  \n\n\n\n\nThe next step is to group the data to understand the number of technical replicates per sample. Sometimes, due to the way the experiment runs, some technical replicates are lost. We just want to make sure what is available for the analysis.\nTwo very important functions are used here to summarise the information. We first need to group the rows that we want to summarise. In this case, we want to group by gene, sample ID and also the treatment + genotype. The group_by is the one to be used. Usually after using group_by, one can summarise the data using the function summarise. In there you create columns similarly to the function mutate, but applying functions to the columns of the grouped dataset. In this case, we use the function n() to count the number of rows in the grouped dataframe.\n\nnb_technical_replicates <- qpcr %>% \n    group_by(group, gene, sample_id) %>%\n    summarise(n = n()) \n\n`summarise()` has grouped output by 'group', 'gene'. You can override using the\n`.groups` argument.\n\n\nThe function tabyl from the package janitor counts the frequency of the specified column. In this case, we want to know the frequency of the number of technical replicates.\n\nnb_technical_replicates %>%\n    janitor::tabyl(n) %>%\n    kableExtra::kbl() %>%\n    kableExtra::kable_classic(full_width = FALSE)\n\n\n\n \n  \n    n \n    n_n \n    percent \n  \n \n\n  \n    3 \n    24 \n    1 \n  \n\n\n\n\n\nWe see that all samples have 3 technical replicates. If you want to inspect the table, the function head shows the first 5 rows of the table.\n\nhead(nb_technical_replicates)\n\n# A tibble: 6 × 4\n# Groups:   group, gene [2]\n  group gene  sample_id     n\n  <chr> <chr> <fct>     <int>\n1 KO C  AKT   26            3\n2 KO C  AKT   27            3\n3 KO C  AKT   28            3\n4 KO C  GAPDH 26            3\n5 KO C  GAPDH 27            3\n6 KO C  GAPDH 28            3"
  },
  {
    "objectID": "chapters/preparing.html#summarizing-the-data",
    "href": "chapters/preparing.html#summarizing-the-data",
    "title": "4  Preparing the data",
    "section": "4.3 Summarizing the data",
    "text": "4.3 Summarizing the data\nNow that we saw the data looks fine at the first level, the average CT values can be calculated. To do this we again use the function group_by and summarise from the dplyr package.\n\nsummarised_qpcr <- qpcr %>% \n    group_by(sample_id, gene, group, genotype, treatment) %>%\n    summarise(\n        mean = mean(ct),\n        sd = sd(ct)\n    )\n\n`summarise()` has grouped output by 'sample_id', 'gene', 'group', 'genotype'.\nYou can override using the `.groups` argument."
  },
  {
    "objectID": "chapters/preparing.html#checkpoint",
    "href": "chapters/preparing.html#checkpoint",
    "title": "4  Preparing the data",
    "section": "4.4 Checkpoint",
    "text": "4.4 Checkpoint\n\nsaveRDS(summarised_qpcr, \"../checkpoints/preparing/summarised_qpcr.rds\")"
  },
  {
    "objectID": "chapters/plotting.html",
    "href": "chapters/plotting.html",
    "title": "5  Plotting",
    "section": "",
    "text": "In this section we will show how to explore qPCR data through plotting. Whenever doing data analysis, it is very important to explore data through data summaries and plots. This way you learn and get a better feeling for the generated data.\nIf you have been following the previous chapters, the data will be ready to do the plotting and data exploration. Here we will introduce the library ggplot2 and we will combine with the pivoting functions we previously learned."
  },
  {
    "objectID": "chapters/plotting.html#visualizing-cycle-thresholds",
    "href": "chapters/plotting.html#visualizing-cycle-thresholds",
    "title": "5  Plotting",
    "section": "5.1 Visualizing cycle thresholds",
    "text": "5.1 Visualizing cycle thresholds\nThe first step is to understand the cycle thresholds obtained in the data, even before normalizing them. This is important as we might find outliers and we check how good the housekeeping genes are.\nMoreover, one important step of the analysis is to check the absolute values of the cycle thresholds. Sometimes the fold changes can be misleading if there are high values of cycle thresholds.\nSince qPCR data usually is already in the long format1, we can directly apply the whole ggplot2 machinery.\nThe idea with ggplot2 is that one can add layers on your plot. You start with an empty canvas by calling the function ggplot and you specify its aesthetics within the function aes. Here we want to plot the cycle threshold by sample id, color by treatment and the shape will be the genotype.\n\np <- ggplot2::ggplot(\n    summarised_qpcr, \n    aes(x = gene, y = mean, color = genotype, shape = treatment)\n)\n\nTo get the points for each group in a way they don’t overlap with each other, we use the function geom_jitter from ggplot2. This function is useful when one of the axis is categorical, which in this case is the gene.\n\np + \n    geom_jitter() +\n    theme_bw()\n\n\n\n\nWe can also modify the theme of the plot by using one of the functions theme_*. Here we use the theme_bw, all the basic options are here: https://ggplot2.tidyverse.org/reference/ggtheme.html.\nAlready from the average cycle threshold plot for each gene we can draw some conclusions. First we see that the loading worked very well for all samples, as the average CT is almost the same for all samples. Also from here we can see a difference in treatments among the WT samples from the AKT gene. Lastly, the control AKT gene from the KO genotype is highly variable."
  },
  {
    "objectID": "chapters/plotting.html#are-there-any-outliers",
    "href": "chapters/plotting.html#are-there-any-outliers",
    "title": "5  Plotting",
    "section": "5.2 Are there any outliers?",
    "text": "5.2 Are there any outliers?\nA common mistake is to use the data as it is. The exploratory analysis is very important as it can uncover outliers. One way to check the presence of weird samples is to plot the average CT values versus their standard deviation. The function geom_point gives a scatterplot. On the other hand, the function labs modifies the name of the axis, title and other things. Here we only change the x and y axis, but to change the title simply modify the argument title within the labs function.\n\nggplot(\n    summarised_qpcr, \n    aes(x = mean, y = sd, color = genotype, shape = treatment)\n) + \n    geom_point() +\n    labs(\n        x = \"Average CT values\",\n        y = \"SD of CT values\"\n    ) +\n    theme_bw()\n\n\n\n\nIt seems that there is no outlier in this case. We can now proceed to the next chapter, in which we normalize the data."
  },
  {
    "objectID": "chapters/normalizing.html",
    "href": "chapters/normalizing.html",
    "title": "6  Normalizing the data",
    "section": "",
    "text": "One crucial step is the delta CT normalization, in which we use the housekeeping genes to correct for the loading in the qPCR. In this small chapter we normalize the data and save it so it can be used during the modelling.\nBefore normalizing we would like to remove the technical samples that look like outliers. This is important because if there is a value that looks plainly wrong, it will affect the results.\nAnd the last step before moving on to the next step is to once again plot the data. Even though we already explored the data once in the last chapter, plotting is never enough, it helps us understand what is going on with the experiments."
  },
  {
    "objectID": "chapters/normalizing.html#delta-ct",
    "href": "chapters/normalizing.html#delta-ct",
    "title": "6  Normalizing the data",
    "section": "6.1 delta CT",
    "text": "6.1 delta CT\nThe classical normalization method is the delta CT. We subtract the geometric average of the housekeeping genes from each average CT value of the genes of interest.\n\n# specify the genes of interest and housekeeping genes, any \n# number of genes can be used here. They are used in the code below\n# during the normalization procedure\ngenes_of_interest <- c(\"AKT\")\nhk_genes <- c(\"GAPDH\")\n\nnormalized_qpcr <- summarised_qpcr %>%\n    group_by() %>%\n    pivot_wider(\n        id_cols = c(\"sample_id\", \"group\", \"genotype\", \"treatment\"),\n        values_from = \"mean\",\n        names_from = \"gene\"\n    ) %>% \n    # apply the operation in each row individually\n    rowwise() %>% \n    mutate(hk_geom = exp(mean(log(!!sym(hk_genes))))) %>%\n    # now we convert back to the long format but only for the \n    # genes of interest, so we can apply for each row the difference\n    pivot_longer(\n        cols = all_of(genes_of_interest),\n        names_to = \"gene\",\n        values_to = \"mean\"\n    ) %>%\n    mutate(dct = mean - hk_geom)\n    \nnormalized_qpcr %>% head\n\n# A tibble: 6 × 9\n  sample_id group genotype treatment GAPDH hk_geom gene   mean    dct\n  <fct>     <chr> <chr>    <chr>     <dbl>   <dbl> <chr> <dbl>  <dbl>\n1 20        WT C  WT       C          17.3    17.3 AKT    16.5 -0.740\n2 21        WT C  WT       C          17.2    17.2 AKT    16.6 -0.567\n3 22        WT C  WT       C          17.3    17.3 AKT    17.0 -0.323\n4 23        WT T  WT       T          17.3    17.3 AKT    17.7  0.440\n5 24        WT T  WT       T          17.2    17.3 AKT    17.8  0.537\n6 25        WT T  WT       T          17.2    17.2 AKT    17.9  0.717\n\n\nNotice here how important it is pivot_longer and pivot_wider. They allow us to perform several operations on our dataset."
  },
  {
    "objectID": "chapters/normalizing.html#exploring-normalized-data",
    "href": "chapters/normalizing.html#exploring-normalized-data",
    "title": "6  Normalizing the data",
    "section": "6.2 Exploring normalized data",
    "text": "6.2 Exploring normalized data\nWith the normalized dataset we can now investigate and compare the groups.\n\nnormalized_qpcr %>% \n    # convert the C and T to control and treated\n    mutate(treatment = ifelse(treatment == \"C\", \"Control\", \"Treated\")) %>%\n    ggplot(aes(y = dct, x = treatment, color = genotype, shape = gene)) + \n    geom_jitter() + \n    labs(x = \"Treatment\", y = expression(Delta*\"CT\")) +\n    theme_bw()\n\n\n\n\nAlready from this plot we see that in the control condition, the KO genotype is highly variable, so it is very unlikely we see any differences, in average between control and the treated condition. But that does not mean anything, it could be that your question is if the treatment stabilizes the KO condition of the gene.\nAnd lastly we compare the CT values with the \\(\\Delta\\)CT values. It is another way to see how well the housekeeping genes are performing.\n\nnormalized_qpcr %>% \n    ggplot(aes(x = mean, y = dct, color = group)) +\n    geom_smooth(\n        method = \"lm\",\n        color = \"black\", \n        alpha = 0.5, \n        size = .1,\n        formula = \"y~x\"\n    ) +\n    geom_point() +\n    theme_bw()"
  },
  {
    "objectID": "chapters/normalizing.html#checkpoint",
    "href": "chapters/normalizing.html#checkpoint",
    "title": "6  Normalizing the data",
    "section": "6.3 Checkpoint",
    "text": "6.3 Checkpoint\n\nsaveRDS(normalized_qpcr, \"../checkpoints/normalizing/normalized_qpcr.rds\")"
  },
  {
    "objectID": "chapters/testing.html",
    "href": "chapters/testing.html",
    "title": "7  Answering questions",
    "section": "",
    "text": "We have been preparing and analysing our data to answer our questions. In this case we have two:\nThe questions will be answered in the next section by using the framework of linear regression. Linear regression is doing almost the same thing as a t-test. Also if you want to test normality of the values this is possible, but since the sample size is very low it is very difficult to reject the null hypothesis that the samples do not follow a normal distribution.\nThe regression framework allows us to extend it to other uses, such as using other types of distributions. One example is when we are dealing with proportions or percentages, usually one would use the gamma distribution instead of the normal distribution to model the data.\nLet’s move to answering the questions!"
  },
  {
    "objectID": "chapters/testing.html#first-question",
    "href": "chapters/testing.html#first-question",
    "title": "7  Answering questions",
    "section": "7.1 First question",
    "text": "7.1 First question\nLet us recap the question here:\n\nIs there any difference between treatment and control in the wild type (WT) condition?\n\nFor this we will need to load once again the packages and our previous checkpoint. R already provides in the base package the function lm to perform linear regression, so this is actually not necessary to load.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(broom)\n\n# we load only the normalized data as this is what will be used when doing\n# the comparisons\nnormalized_qpcr <- readRDS(\"../checkpoints/normalizing/normalized_qpcr.rds\")\n\nThe code below executes the comparison and prints the output. What we want to read from the linear regression output is the estimate of the slope, that will represent the difference between the two groups! One nice thing of using linear regression is that you get the difference values between your conditions, and that might be used to further interpret the results.\n\nanalysis_first_question <- normalized_qpcr %>% \n    # first filter just for the WT\n    dplyr::filter(grepl(\"WT\", group)) %>%\n    # Now we factor so the first level is control and the difference\n    # then represents treatment - control.\n    dplyr::mutate(group = factor(group, levels = c(\"WT C\", \"WT T\"))) %>%\n    # perform the linear regression\n    lm(dct ~ group, data = .) %>%\n    # tidy up the results so we can display\n    broom::tidy()\n    \n\nanalysis_first_question %>% \n    kableExtra::kbl() %>%\n    kableExtra::kable_classic(full_width = FALSE)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    -0.5433333 \n    0.1028963 \n    -5.280396 \n    0.0061685 \n  \n  \n    groupWT T \n    1.1077778 \n    0.1455174 \n    7.612684 \n    0.0015982 \n  \n\n\n\n\n\nTo calculate the fold change one needs to flip the sign for the estimate, since an increase of CT is actually a decrease in expression. The total fold change is 0.4640082 and log fold change is -1.1077778.\nThe way to calculate the fold change is \\(2^{(-\\text{estimate})}\\), where \\(\\text{estimate}\\) corresponds to the second row and second column of the table above. And the log fold change is just the negative value of \\(\\text{estimate}\\).\nThe conclusion for this question is that there is indeed a decrease in AKT expression levels in the treated condition for the WT genotype. We had already seen this from the plots of the previous chapters.\nI would recommend to report this values along with the previous plots, as the CT values are also an important aspect of the analysis, as an increase of 30 to 31 is not the same as 16 to 17."
  },
  {
    "objectID": "chapters/testing.html#second-question",
    "href": "chapters/testing.html#second-question",
    "title": "7  Answering questions",
    "section": "7.2 Second question",
    "text": "7.2 Second question\nWe now move on to the second question.\n\nDoes the effect of treatment depends on genotype?\n\nHere we are interested in the interaction between the genotype and treatment. R has an special way to encode this when doing linear regression, by using the star symbol *.\n\nanalysis_second_question <- normalized_qpcr %>% \n    dplyr::mutate(\n        group = factor(group, levels = c(\"WT C\", \"WT T\", \"KO C\", \"KO T\")),\n        genotype = factor(genotype, levels = c(\"WT\", \"KO\"))\n    ) %>%\n    # notice here the star. we are now interested in the interaction\n    lm(dct ~ genotype * treatment, data = .) %>%\n    broom::tidy()\n    \nanalysis_second_question %>% \n    kableExtra::kbl() %>%\n    kableExtra::kable_classic(full_width = FALSE)\n\n\n\n \n  \n    term \n    estimate \n    std.error \n    statistic \n    p.value \n  \n \n\n  \n    (Intercept) \n    -0.5433333 \n    0.4440748 \n    -1.2235175 \n    0.2559465 \n  \n  \n    genotypeKO \n    0.9066667 \n    0.6280167 \n    1.4436984 \n    0.1868167 \n  \n  \n    treatmentT \n    1.1077778 \n    0.6280167 \n    1.7639305 \n    0.1157518 \n  \n  \n    genotypeKO:treatmentT \n    -0.3388889 \n    0.8881497 \n    -0.3815673 \n    0.7127173 \n  \n\n\n\n\n\nWe had already seen that actually in the knockout condition there was a lot of variability. This is reflected in the results here. The last line of the table above presents the result that interest us, the interaction between treatment and genotype. We see that the p-value is around 0.71, so we don’t have enough evidence to reject the null hypothesis, which is there is no effect in the genotype and treatment."
  }
]